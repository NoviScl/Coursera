{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data and packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from preprocessed_mnist import load_dataset\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = load_dataset()\n",
    "print(X_train.shape, y_train.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.imshow(X_train[0], cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "s = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declaration of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "nb_classes = 10\n",
    "targets = y_train.reshape(-1)\n",
    "y_train_flat = np.eye(nb_classes)[targets]\n",
    "targets_test = y_test.reshape(-1)\n",
    "y_test_flat = np.eye(nb_classes)[targets_test]\n",
    "\n",
    "num = 150\n",
    "batch_size = 500\n",
    "num_iter = 12000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_X = tf.placeholder('float32', shape=(None, X_train_flat.shape[1]))\n",
    "input_y = tf.placeholder('float32', shape=(None, 10))\n",
    "weights = tf.Variable(np.zeros((X_train_flat.shape[1],10),dtype = 'float32')) # tf.Variable(np.random.randint(5, size=(X.shape[1],1))/5.0,dtype=tf.float32) # \n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining nn activation functions, loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hidden_layer_activation(input,size_in,size_out):\n",
    "    WW = tf.Variable(tf.truncated_normal([size_in,size_out],stddev=0.1))\n",
    "    bb = tf.Variable(tf.truncated_normal([size_out],stddev=0.1))\n",
    "    activation = tf.sigmoid(tf.matmul(input,WW)+bb)\n",
    "    return activation\n",
    "def output_layer_activation(input,size_in,size_out):\n",
    "    WW = tf.Variable(tf.truncated_normal([size_in,size_out],stddev=0.1))\n",
    "    bb = tf.Variable(tf.truncated_normal([size_out],stddev=0.1))\n",
    "    activation = tf.nn.softmax(tf.matmul(input,WW)+bb)\n",
    "    return activation\n",
    "\n",
    "\n",
    "hidden = hidden_layer_activation(input_X,784,num)\n",
    "output = output_layer_activation(hidden,num,10)\n",
    "\n",
    "#predicted_y = tf.nn.softmax(tf.matmul(input_X, weights) + b)\n",
    "#loss = tf.nn.softmax_cross_entropy_with_logits(logits = tf.matmul(hidden, weights) + b, labels=input_y)\n",
    "#loss = tf.reduce_mean(-tf.log(output)*input_y -tf.log(1-output)*(1-input_y))\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(input_y * tf.log(output), reduction_indices=[1]))\n",
    "optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "correct_prediction = tf.equal(tf.argmax(output,1), tf.argmax(input_y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_train = []\n",
    "loss_test = []\n",
    "iterations = []\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "s.run(tf.global_variables_initializer())\n",
    "start_time = time.time()\n",
    "for i in range(num_iter):\n",
    "    batch = np.random.choice(X_train_flat.shape[0], batch_size)\n",
    "    s.run(optimizer, {input_X: X_train_flat[batch,:], input_y: y_train_flat[batch,:]})\n",
    "    if (i+1)%500==0:\n",
    "        loss_train_i = s.run(loss, {input_X: X_train_flat, input_y: y_train_flat})\n",
    "        loss_test_i = s.run(loss, {input_X: X_test_flat, input_y: y_test_flat})\n",
    "        loss_train.append(loss_train_i)\n",
    "        loss_test.append(loss_test_i)\n",
    "        iterations.append(i+1)\n",
    "        #print(\"loss at iter %i:%.4f\" % (i, loss_i))\n",
    "        #print(\"train auc:\", roc_auc_score(y_train_flat, s.run(output, {input_X:X_train_flat})))\n",
    "        a = s.run(accuracy, feed_dict={input_X: X_train_flat, input_y: y_train_flat})\n",
    "        print(\"train accuracy no \",i+1,\" :\",a*100,\"%\")\n",
    "        a2 = s.run(accuracy, feed_dict={input_X: X_test_flat,input_y: y_test_flat})\n",
    "        #a2 = accuracy.eval(feed_dict={input_X: X_test_flat, input_y: y_test_flat})\n",
    "        print(\"test accuracy no \",i+1,\" :\",a2*100,\"%\")\n",
    "        print(\"Current execution time: \",(time.time()-start_time)/60, \" minutes\")\n",
    "        #print(\"test auc:\", roc_auc_score(y_test_flat, s.run(output, {input_X:X_test_flat})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = s.run(accuracy, feed_dict={input_X: X_test_flat,input_y: y_test_flat})\n",
    "print(\"final test accuracy :\",acc*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and test loss chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(iterations,loss_train,'r--',label='train loss')\n",
    "plt.plot(iterations,loss_test,'b--',label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
